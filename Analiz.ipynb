{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makina Öğrenmesi Modelleri İle Sınıflandırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, numpy, textblob, string, xgboost\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time\n",
    "import TweetAnaliz as tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('yorumlar.csv', encoding ='utf_8', sep='\"')\n",
    "data['Sentiment'] = 1\n",
    "data.Sentiment.iloc[10003:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Sentiment\"].replace(0, value = \"negatif\", inplace = True)\n",
    "data[\"Sentiment\"].replace(1, value = \"pozitif\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['yorum,Positivity', 'Sentiment'], dtype='object')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns ={'yorum,Positivity':'yorum'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.Sentiment == \"negatif\") | (data.Sentiment == \"pozitif\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yorum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negatif</th>\n",
       "      <td>9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pozitif</th>\n",
       "      <td>10003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           yorum\n",
       "Sentiment       \n",
       "negatif     9996\n",
       "pozitif    10003"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"Sentiment\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"text\"] = data[\"yorum\"]\n",
    "df[\"label\"] = data[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-152-98c4109d9c61>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-152-98c4109d9c61>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df.drop('id', 1)    İd satırını siler\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df.drop('id', 1)    İd satırını siler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(df[\"text\"],df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y = encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Değişken Mühendisliği \n",
    "\n",
    "### Count Vectors\n",
    "Kelime vektörleri oluşturacağız ve eğer metin verileri bu kelime kelimesini içeriyorsa, bu boyuta bir tane koyacağız. Bu kelimeyle her karşılaştığımızda sayıyı artıracağız, kelimeyi bir kez bile bulamadığımız her yerde 0'lar bırakacağız.\n",
    "Bunun sonucu çok büyük vektörler olacaktır, eğer bunları gerçek metin verilerinde kullanırsak, metin verilerimizin kelime içeriğinin çok doğru sayılarını alırız. Ne yazık ki, bu herhangi bir anlamsal veya ilişkisel bilgi ile kullanım sağlamaz, ancak bu iyi çünkü bu tekniği kullanmanın amacı bu değildir.\n",
    "Link: https://towardsdatascience.com/natural-language-processing-count-vectorization-with-scikit-learn-e7804269bb5e\n",
    "### TF-IDF Vectors (words, characters, n-grams)\n",
    "Bir Terim Sıklığı verilen bir dokümanda bir kelimenin kaç kez meydana geldiğinin (kelime torbasıyla eşanlamlı) bir sayıdır.Ters Belge Frekansı bir kelime belgelerin derleminden meydana sayısıdır. tf-idf kelimeleri ne kadar önemli olduklarına göre ağırlıklandırmak için kullanılır. Birçok belgede sık kullanılan kelimeler daha düşük bir ağırlığa sahip olurken, nadir olanlar daha yüksek bir ağırlığa sahip olacaktır.\n",
    "\n",
    "TF(t) = (Bir t teriminin bir dökümanda gözlenme frekansı) / (dökümandaki toplam terim sayısı) \n",
    "\n",
    "IDF(t) = log_e(Toplam döküman sayısı / içinde t terimi olan belge sayısı)\n",
    "\n",
    "Link: https://medium.com/@acrosson/summarize-documents-using-tf-idf-bdee8f60b71\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer() \n",
    "vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_count = vectorizer.transform(train_x)\n",
    "x_test_count = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01', '02', '03']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[5:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_count.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-ID\n",
    "\n",
    "TF(t) = (Bir t teriminin bir dökümanda gözlenme frekansı) / (dökümandaki toplam terim sayısı)\n",
    "\n",
    "IDF(t) = log_e(Toplam döküman sayısı / içinde t terimi olan belge sayısı)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_word_vectorizer = TfidfVectorizer()\n",
    "tf_idf_word_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf_idf_word = tf_idf_word_vectorizer.transform(train_x)\n",
    "x_test_tf_idf_word = tf_idf_word_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(2, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_ngram_vectorizer = TfidfVectorizer(ngram_range = (2,3))\n",
    "tf_idf_ngram_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf_idf_ngram = tf_idf_ngram_vectorizer.transform(train_x)\n",
    "x_test_tf_idf_ngram = tf_idf_ngram_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CharLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(2, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_chars_vectorizer = TfidfVectorizer(analyzer = \"char\", ngram_range = (2,3))\n",
    "tf_idf_chars_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf_idf_chars = tf_idf_chars_vectorizer.transform(train_x)\n",
    "x_test_tf_idf_chars = tf_idf_chars_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makine Öğrenmesi ile Sentiment Sınıflandırması"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lojistik Regrasyon scikit-learn kütüphanesi\n",
    "\n",
    "\n",
    "Duyarlılık Analizi, belirli bir şeye göre birinin hissiyatını yargılamak veya duygularını anlamlandırmak için kullanılan bir yöntemdir. Temel olarak bir metin işleme (text processing) işlemi olup verilen metinin duygusal olarak\n",
    "ifade etmek istediği sınıfı belirlemeyi amaçlar.\n",
    "- Metinlerin üzerinden amaca yönelik olarak fikir çıkarımı yapılırken kelime sayısı, isim, sıfat, zarf veya fiil gibi kelimelerin sıklıkları (frekansları) üzerinden fikir madenciliği yapılmasına verilen isimdir. (Word2vec , TF/ IDF)\n",
    "- Frekans tabanlı fikir madenciliğinde, öncelikle isim kelime grupları bulunarak bunlar uzunluklarına, kullanımdaki gerekliliklerine ve olumlu olumsuz kutupsallığına göre sınıflandırılmaktadır.\n",
    "\n",
    "### https://medium.com/operations-management-t%C3%BCrkiye/lojistik-regresyon-ile-duygu-analizi-d9d0b8e7b4e5\n",
    "### https://www.nltk.org/howto/sentiment.html\n",
    "### https://www.nltk.org/api/nltk.sentiment.html#module-nltk.sentiment\n",
    "### https://nlpforhackers.io/sentiment-analysis-intro/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lojistik Regrasyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors Doğruluk Oranı: 0.8538\n",
      "Word-Level TF-IDF Doğruluk Oranı: 0.86\n",
      "N-GRAM TF-IDF Doğruluk Oranı: 0.8176\n",
      "CHARLEVEL Doğruluk Oranı: 0.9568000000000001\n"
     ]
    }
   ],
   "source": [
    "loj = linear_model.LogisticRegression()\n",
    "loj_model = loj.fit(x_train_count, train_y)\n",
    "accuracy = model_selection.cross_val_score(loj_model, x_test_count, test_y, cv = 10).mean()\n",
    "accuracy=float(accuracy)\n",
    "print(\"Count Vectors Doğruluk Oranı:\", accuracy)\n",
    "\n",
    "loj = linear_model.LogisticRegression()\n",
    "loj_model = loj.fit(x_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(loj_model, x_test_tf_idf_word, test_y, cv = 10).mean()\n",
    "print(\"Word-Level TF-IDF Doğruluk Oranı:\", accuracy)\n",
    "\n",
    "loj = linear_model.LogisticRegression()\n",
    "loj_model = loj.fit(x_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(loj_model, x_test_tf_idf_ngram, test_y, cv = 10).mean()\n",
    "print(\"N-GRAM TF-IDF Doğruluk Oranı:\", accuracy)\n",
    "\n",
    "loj = linear_model.LogisticRegression()\n",
    "loj_model = loj.fit(x_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(loj_model, x_test_tf_idf_chars, test_y, cv = 10).mean()\n",
    "print(\"CHARLEVEL Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navy Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors Doğruluk Oranı: 0.865\n",
      "Word-Level TF-IDF Doğruluk Oranı: 0.8744\n",
      "N-GRAM TF-IDF Doğruluk Oranı: 0.8366\n",
      "CHARLEVEL Doğruluk Oranı: 0.8914\n"
     ]
    }
   ],
   "source": [
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(x_train_count,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, x_test_count, test_y, cv = 10).mean()\n",
    "print(\"Count Vectors Doğruluk Oranı:\", accuracy)\n",
    "\n",
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(x_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, x_test_tf_idf_word, test_y, cv = 10).mean()\n",
    "print(\"Word-Level TF-IDF Doğruluk Oranı:\", accuracy)\n",
    "\n",
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(x_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, x_test_tf_idf_ngram, test_y, cv = 10).mean()\n",
    "print(\"N-GRAM TF-IDF Doğruluk Oranı:\", accuracy)\n",
    "\n",
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(x_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, x_test_tf_idf_chars, test_y, cv = 10).mean()\n",
    "\n",
    "print(\"CHARLEVEL Doğruluk Oranı:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors Doğruluk Oranı: 0.8366\n",
      "Word-Level TF-IDF Doğruluk Oranı: 0.8290000000000001\n",
      "N-GRAM TF-IDF Doğruluk Oranı: 0.7792000000000001\n",
      "CHARLEVEL Doğruluk Oranı: 0.9974000000000001\n"
     ]
    }
   ],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = rf.fit(x_train_count,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, x_test_count, test_y,cv = 10).mean()\n",
    "print(\"Count Vectors Doğruluk Oranı:\", accuracy)\n",
    "\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = rf.fit(x_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, x_test_tf_idf_word, test_y, cv = 10).mean()\n",
    "print(\"Word-Level TF-IDF Doğruluk Oranı:\", accuracy)\n",
    "\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = rf.fit(x_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, x_test_tf_idf_ngram, test_y, cv = 10).mean()\n",
    "print(\"N-GRAM TF-IDF Doğruluk Oranı:\", accuracy)\n",
    "\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = rf.fit(x_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, x_test_tf_idf_chars, test_y, cv = 10).mean()\n",
    "print(\"CHARLEVEL Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `RandomForestClassifier()` not found.\n"
     ]
    }
   ],
   "source": [
    "?RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors Doğruluk Oranı: 0.7830000000000001\n",
      "Word-Level TF-IDF Doğruluk Oranı: 0.7824\n",
      "N-GRAM TF-IDF Doğruluk Oranı: 0.6902\n",
      "CHARLEVEL Doğruluk Oranı: 1.0\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(x_train_count,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, x_test_count, test_y, cv = 10).mean()\n",
    "print(\"Count Vectors Doğruluk Oranı:\", accuracy)\n",
    "\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(x_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, x_test_tf_idf_word, test_y, cv = 10).mean()\n",
    "print(\"Word-Level TF-IDF Doğruluk Oranı:\", accuracy)\n",
    "\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(x_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, x_test_tf_idf_ngram, test_y, cv = 10).mean()\n",
    "print(\"N-GRAM TF-IDF Doğruluk Oranı:\", accuracy)\n",
    "\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(x_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, x_test_tf_idf_chars, test_y, cv = 10).mean()\n",
    "print(\"CHARLEVEL Doğruluk Oranı:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('ArelUnuversitesi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radyosivrisinek kafaradyo radyoland yılönceben...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bbsimsek arel üniversitesi metoroloji mühendis...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ogrencidekani çocukların yeri eğitim öğretim y...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ogrencidekani çocukların yeri eğitim öğretim y...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>çocukların yeri eğitim öğretim yuvaları parkla...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>şimdi bardağımızı önümüze alıyoruz süslemek is...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>kavanozumuzun kapağını kapattığımızdan emin ol...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>ilk olarak çay kaşığı granül kahvemizi kavanoz...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>malzemeler küçük boy kavanoz süt granül kahvet...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>buzlu soğuk kahve tarifi httpstcolkhikfxaf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment\n",
       "0     radyosivrisinek kafaradyo radyoland yılönceben...          2\n",
       "1     bbsimsek arel üniversitesi metoroloji mühendis...          2\n",
       "2     ogrencidekani çocukların yeri eğitim öğretim y...          2\n",
       "3     ogrencidekani çocukların yeri eğitim öğretim y...          2\n",
       "4     çocukların yeri eğitim öğretim yuvaları parkla...          2\n",
       "...                                                 ...        ...\n",
       "4398  şimdi bardağımızı önümüze alıyoruz süslemek is...          2\n",
       "4399  kavanozumuzun kapağını kapattığımızdan emin ol...          2\n",
       "4400  ilk olarak çay kaşığı granül kahvemizi kavanoz...          2\n",
       "4401  malzemeler küçük boy kavanoz süt granül kahvet...          2\n",
       "4402         buzlu soğuk kahve tarifi httpstcolkhikfxaf          2\n",
       "\n",
       "[4403 rows x 2 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2331"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].iloc[7672:10003].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Analiz edilen verinin kayıt edileceği csv dosyaya bir ad veriniz : ArelUnuversitesi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "İşlem tamamlandı\n",
      "0.0 dakikada toplam 2331 tweet analiz edildi\n"
     ]
    }
   ],
   "source": [
    "rf = TfidfVectorizer(analyzer = \"char\", ngram_range = (2,3))\n",
    "rf.fit(train_x)\n",
    "     \n",
    "dosya=input('Analiz edilen verinin kayıt edileceği csv dosyaya bir ad veriniz :')\n",
    "\n",
    "for x in range(df['text'].count()):\n",
    "    baslangic=time.time()\n",
    "    \n",
    "    veri= pd.Series(df['text'][x])\n",
    "    veri = rf.transform(veri)\n",
    "\n",
    "    sonuc=rf_model.predict(veri)\n",
    "   \n",
    "    sonuc=int(sonuc)\n",
    "    \n",
    "    if sonuc == 1 :\n",
    "        df['sentiment'][x]=sonuc\n",
    "    else:\n",
    "        df['sentiment'][x]=sonuc\n",
    "df.to_csv(dosya+'.csv', mode='w',index=False)\n",
    "bitis=time.time()\n",
    "print('İşlem tamamlandı')\n",
    "print('{} dakikada toplam {} tweet analiz edildi'.format(round((bitis-baslangic)/60,2),sayi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radyosivrisinek kafaradyo radyoland yılönceben...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bbsimsek arel üniversitesi metoroloji mühendis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ogrencidekani çocukların yeri eğitim öğretim y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ogrencidekani çocukların yeri eğitim öğretim y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>çocukların yeri eğitim öğretim yuvaları parkla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>şimdi bardağımızı önümüze alıyoruz süslemek is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>kavanozumuzun kapağını kapattığımızdan emin ol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>ilk olarak çay kaşığı granül kahvemizi kavanoz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>malzemeler küçük boy kavanoz süt granül kahvet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>buzlu soğuk kahve tarifi httpstcolkhikfxaf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment\n",
       "0     radyosivrisinek kafaradyo radyoland yılönceben...          1\n",
       "1     bbsimsek arel üniversitesi metoroloji mühendis...          1\n",
       "2     ogrencidekani çocukların yeri eğitim öğretim y...          0\n",
       "3     ogrencidekani çocukların yeri eğitim öğretim y...          0\n",
       "4     çocukların yeri eğitim öğretim yuvaları parkla...          1\n",
       "...                                                 ...        ...\n",
       "4398  şimdi bardağımızı önümüze alıyoruz süslemek is...          1\n",
       "4399  kavanozumuzun kapağını kapattığımızdan emin ol...          1\n",
       "4400  ilk olarak çay kaşığı granül kahvemizi kavanoz...          1\n",
       "4401  malzemeler küçük boy kavanoz süt granül kahvet...          1\n",
       "4402         buzlu soğuk kahve tarifi httpstcolkhikfxaf          1\n",
       "\n",
       "[4403 rows x 2 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>timeline</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>location</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1271463341144276998</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1077402606...</td>\n",
       "      <td>@RadyoSivrisinek @kafaradyo @radyoland #10YılÖ...</td>\n",
       "      <td>2020-06-12 15:24:17</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>SevdaAkcasu</td>\n",
       "      <td>1102</td>\n",
       "      <td>Ankara'da</td>\n",
       "      <td>[{'text': '10YılÖnceBen', 'indices': [39, 52]}]</td>\n",
       "      <td>SevdaAkcasu</td>\n",
       "      <td>Ankara'da</td>\n",
       "      <td>8065</td>\n",
       "      <td>1082</td>\n",
       "      <td>12161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1270464754205831170</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1270807390...</td>\n",
       "      <td>SARI PAPATYA GİTMEMEN LAZIMDI \\n.\\n.\\n.\\n#surv...</td>\n",
       "      <td>2020-06-09 21:16:16</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>arel_ern</td>\n",
       "      <td>224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'text': 'survivor2020', 'indices': [37, 50]}]</td>\n",
       "      <td>arel_ern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1658</td>\n",
       "      <td>267</td>\n",
       "      <td>5312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1270325535890182145</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1267557561...</td>\n",
       "      <td>🦄|-Hayatınızın yaklaşık 6’da 1’i çarşamba günl...</td>\n",
       "      <td>2020-06-09 12:03:03</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>selfcare__arel_</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>selfcare__arel_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1270326827748405250</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1267557561...</td>\n",
       "      <td>🦄| Daha fazla bu tarz gönderi gelmesi için beğ...</td>\n",
       "      <td>2020-06-09 12:08:11</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>selfcare__arel_</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>selfcare__arel_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1270394791604477955</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1269030619...</td>\n",
       "      <td>@zalimmgeceler @izellll_ Yaptım zaten Arel üni...</td>\n",
       "      <td>2020-06-09 16:38:15</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>fuurkanates</td>\n",
       "      <td>52558</td>\n",
       "      <td>Bursa</td>\n",
       "      <td>[]</td>\n",
       "      <td>fuurkanates</td>\n",
       "      <td>Bursa</td>\n",
       "      <td>28710</td>\n",
       "      <td>35807</td>\n",
       "      <td>39586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1270630907666407424</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1242186829...</td>\n",
       "      <td>RT @birsucann: Dünyada; 35 ülkede heykeli, 120...</td>\n",
       "      <td>2020-06-10 08:16:30</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>337</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Hsyn_Arel_Ayse</td>\n",
       "      <td>23</td>\n",
       "      <td>Buca, İzmir</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hsyn_Arel_Ayse</td>\n",
       "      <td>Buca, İzmir</td>\n",
       "      <td>281</td>\n",
       "      <td>174</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1271113674397233153</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1271019329...</td>\n",
       "      <td>~Onlara ihtiyacın olduğu zaman kaybolurlar \\n~...</td>\n",
       "      <td>2020-06-11 16:14:50</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>arel_selfcare</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>arel_selfcare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1270295988129992704</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1270461971...</td>\n",
       "      <td>RT @SufleninVasisi: AREL Üniversitesi 2016 mez...</td>\n",
       "      <td>2020-06-09 10:05:39</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>kivircikcik23</td>\n",
       "      <td>482</td>\n",
       "      <td>İstanbul, Türkiye</td>\n",
       "      <td>[{'text': 'muratyurtgül', 'indices': [103, 116]}]</td>\n",
       "      <td>kivircikcik23</td>\n",
       "      <td>İstanbul, Türkiye</td>\n",
       "      <td>1447</td>\n",
       "      <td>312</td>\n",
       "      <td>15869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1271117765995384832</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1271019329...</td>\n",
       "      <td>💫|Kötü arkadaşlarını tespit etme https://t.co/...</td>\n",
       "      <td>2020-06-11 16:31:06</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>arel_selfcare</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>arel_selfcare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1270828287699361792</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1249042250...</td>\n",
       "      <td>@pekiiiozamaan @bbarisgunes Yankı Arel</td>\n",
       "      <td>2020-06-10 21:20:49</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>buseeazmn</td>\n",
       "      <td>871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>buseeazmn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2844</td>\n",
       "      <td>60</td>\n",
       "      <td>50752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                  profile_image_url  \\\n",
       "0   1271463341144276998  http://pbs.twimg.com/profile_images/1077402606...   \n",
       "59  1270464754205831170  http://pbs.twimg.com/profile_images/1270807390...   \n",
       "70  1270325535890182145  http://pbs.twimg.com/profile_images/1267557561...   \n",
       "69  1270326827748405250  http://pbs.twimg.com/profile_images/1267557561...   \n",
       "67  1270394791604477955  http://pbs.twimg.com/profile_images/1269030619...   \n",
       "..                  ...                                                ...   \n",
       "55  1270630907666407424  http://pbs.twimg.com/profile_images/1242186829...   \n",
       "18  1271113674397233153  http://pbs.twimg.com/profile_images/1271019329...   \n",
       "77  1270295988129992704  http://pbs.twimg.com/profile_images/1270461971...   \n",
       "17  1271117765995384832  http://pbs.twimg.com/profile_images/1271019329...   \n",
       "43  1270828287699361792  http://pbs.twimg.com/profile_images/1249042250...   \n",
       "\n",
       "                                                 text           created_at  \\\n",
       "0   @RadyoSivrisinek @kafaradyo @radyoland #10YılÖ...  2020-06-12 15:24:17   \n",
       "59  SARI PAPATYA GİTMEMEN LAZIMDI \\n.\\n.\\n.\\n#surv...  2020-06-09 21:16:16   \n",
       "70  🦄|-Hayatınızın yaklaşık 6’da 1’i çarşamba günl...  2020-06-09 12:03:03   \n",
       "69  🦄| Daha fazla bu tarz gönderi gelmesi için beğ...  2020-06-09 12:08:11   \n",
       "67  @zalimmgeceler @izellll_ Yaptım zaten Arel üni...  2020-06-09 16:38:15   \n",
       "..                                                ...                  ...   \n",
       "55  RT @birsucann: Dünyada; 35 ülkede heykeli, 120...  2020-06-10 08:16:30   \n",
       "18  ~Onlara ihtiyacın olduğu zaman kaybolurlar \\n~...  2020-06-11 16:14:50   \n",
       "77  RT @SufleninVasisi: AREL Üniversitesi 2016 mez...  2020-06-09 10:05:39   \n",
       "17  💫|Kötü arkadaşlarını tespit etme https://t.co/...  2020-06-11 16:31:06   \n",
       "43             @pekiiiozamaan @bbarisgunes Yankı Arel  2020-06-10 21:20:49   \n",
       "\n",
       "                                             timeline  retweeted  \\\n",
       "0   <bound method User.timeline of User(_api=<twee...      False   \n",
       "59  <bound method User.timeline of User(_api=<twee...      False   \n",
       "70  <bound method User.timeline of User(_api=<twee...      False   \n",
       "69  <bound method User.timeline of User(_api=<twee...      False   \n",
       "67  <bound method User.timeline of User(_api=<twee...      False   \n",
       "..                                                ...        ...   \n",
       "55  <bound method User.timeline of User(_api=<twee...      False   \n",
       "18  <bound method User.timeline of User(_api=<twee...      False   \n",
       "77  <bound method User.timeline of User(_api=<twee...      False   \n",
       "17  <bound method User.timeline of User(_api=<twee...      False   \n",
       "43  <bound method User.timeline of User(_api=<twee...      False   \n",
       "\n",
       "    retweet_count               source user_screen_name  user_followers_count  \\\n",
       "0               0  Twitter for Android      SevdaAkcasu                  1102   \n",
       "59              0   Twitter for iPhone         arel_ern                   224   \n",
       "70              0   Twitter for iPhone  selfcare__arel_                     4   \n",
       "69              0   Twitter for iPhone  selfcare__arel_                     4   \n",
       "67              0  Twitter for Android      fuurkanates                 52558   \n",
       "..            ...                  ...              ...                   ...   \n",
       "55            337   Twitter for iPhone   Hsyn_Arel_Ayse                    23   \n",
       "18              1  Twitter for Android    arel_selfcare                     2   \n",
       "77              7   Twitter for iPhone    kivircikcik23                   482   \n",
       "17              0  Twitter for Android    arel_selfcare                     2   \n",
       "43              0  Twitter for Android        buseeazmn                   871   \n",
       "\n",
       "        user_location                                           Hashtags  \\\n",
       "0          Ankara'da     [{'text': '10YılÖnceBen', 'indices': [39, 52]}]   \n",
       "59                NaN    [{'text': 'survivor2020', 'indices': [37, 50]}]   \n",
       "70                NaN                                                 []   \n",
       "69                NaN                                                 []   \n",
       "67              Bursa                                                 []   \n",
       "..                ...                                                ...   \n",
       "55        Buca, İzmir                                                 []   \n",
       "18                NaN                                                 []   \n",
       "77  İstanbul, Türkiye  [{'text': 'muratyurtgül', 'indices': [103, 116]}]   \n",
       "17                NaN                                                 []   \n",
       "43                NaN                                                 []   \n",
       "\n",
       "        screen_name           location  statuses_count  friends_count  \\\n",
       "0       SevdaAkcasu         Ankara'da             8065           1082   \n",
       "59         arel_ern                NaN            1658            267   \n",
       "70  selfcare__arel_                NaN             178              3   \n",
       "69  selfcare__arel_                NaN             178              3   \n",
       "67      fuurkanates              Bursa           28710          35807   \n",
       "..              ...                ...             ...            ...   \n",
       "55   Hsyn_Arel_Ayse        Buca, İzmir             281            174   \n",
       "18    arel_selfcare                NaN              11              2   \n",
       "77    kivircikcik23  İstanbul, Türkiye            1447            312   \n",
       "17    arel_selfcare                NaN              11              2   \n",
       "43        buseeazmn                NaN            2844             60   \n",
       "\n",
       "    favourites_count  sentiment  \n",
       "0              12161          1  \n",
       "59              5312          1  \n",
       "70                 5          1  \n",
       "69                 5          1  \n",
       "67             39586          1  \n",
       "..               ...        ...  \n",
       "55               475          0  \n",
       "18                 0          0  \n",
       "77             15869          0  \n",
       "17                 0          0  \n",
       "43             50752          0  \n",
       "\n",
       "[100 rows x 18 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='sentiment',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "cümle= pd.Series('Bugün hava çok iyi değil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rf = TfidfVectorizer(analyzer = \"char\", ngram_range = (2,3))\n",
    "rf.fit(train_x)\n",
    "\n",
    "veri = rf.transform(cümle)\n",
    "\n",
    "sonuc=rf_model.predict(veri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer = \"char\", ngram_range = (2,3))\n",
    "tf.fit(train_x)\n",
    "\n",
    "veri = tf.transform(cümle)\n",
    "sonuc=loj_model.predict(veri) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "sentiment      \n",
       "0          1452\n",
       "1          2951"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
