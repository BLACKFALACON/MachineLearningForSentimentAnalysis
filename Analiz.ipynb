{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makina Ã–ÄŸrenmesi Modelleri Ä°le SÄ±nÄ±flandÄ±rma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, numpy, textblob, string, xgboost\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time\n",
    "import TweetAnaliz as tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('yorumlar.csv', encoding ='utf_8', sep='\"')\n",
    "data['Sentiment'] = 1\n",
    "data.Sentiment.iloc[10003:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Sentiment\"].replace(0, value = \"negatif\", inplace = True)\n",
    "data[\"Sentiment\"].replace(1, value = \"pozitif\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['yorum,Positivity', 'Sentiment'], dtype='object')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns ={'yorum,Positivity':'yorum'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.Sentiment == \"negatif\") | (data.Sentiment == \"pozitif\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yorum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negatif</th>\n",
       "      <td>9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pozitif</th>\n",
       "      <td>10003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           yorum\n",
       "Sentiment       \n",
       "negatif     9996\n",
       "pozitif    10003"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"Sentiment\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"text\"] = data[\"yorum\"]\n",
    "df[\"label\"] = data[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-152-98c4109d9c61>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-152-98c4109d9c61>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df.drop('id', 1)    Ä°d satÄ±rÄ±nÄ± siler\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df.drop('id', 1)    Ä°d satÄ±rÄ±nÄ± siler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(df[\"text\"],df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y = encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeÄŸiÅŸken MÃ¼hendisliÄŸi \n",
    "\n",
    "### Count Vectors\n",
    "Kelime vektÃ¶rleri oluÅŸturacaÄŸÄ±z ve eÄŸer metin verileri bu kelime kelimesini iÃ§eriyorsa, bu boyuta bir tane koyacaÄŸÄ±z. Bu kelimeyle her karÅŸÄ±laÅŸtÄ±ÄŸÄ±mÄ±zda sayÄ±yÄ± artÄ±racaÄŸÄ±z, kelimeyi bir kez bile bulamadÄ±ÄŸÄ±mÄ±z her yerde 0'lar bÄ±rakacaÄŸÄ±z.\n",
    "Bunun sonucu Ã§ok bÃ¼yÃ¼k vektÃ¶rler olacaktÄ±r, eÄŸer bunlarÄ± gerÃ§ek metin verilerinde kullanÄ±rsak, metin verilerimizin kelime iÃ§eriÄŸinin Ã§ok doÄŸru sayÄ±larÄ±nÄ± alÄ±rÄ±z. Ne yazÄ±k ki, bu herhangi bir anlamsal veya iliÅŸkisel bilgi ile kullanÄ±m saÄŸlamaz, ancak bu iyi Ã§Ã¼nkÃ¼ bu tekniÄŸi kullanmanÄ±n amacÄ± bu deÄŸildir.\n",
    "Link: https://towardsdatascience.com/natural-language-processing-count-vectorization-with-scikit-learn-e7804269bb5e\n",
    "### TF-IDF Vectors (words, characters, n-grams)\n",
    "Bir Terim SÄ±klÄ±ÄŸÄ± verilen bir dokÃ¼manda bir kelimenin kaÃ§ kez meydana geldiÄŸinin (kelime torbasÄ±yla eÅŸanlamlÄ±) bir sayÄ±dÄ±r.Ters Belge FrekansÄ± bir kelime belgelerin derleminden meydana sayÄ±sÄ±dÄ±r. tf-idf kelimeleri ne kadar Ã¶nemli olduklarÄ±na gÃ¶re aÄŸÄ±rlÄ±klandÄ±rmak iÃ§in kullanÄ±lÄ±r. BirÃ§ok belgede sÄ±k kullanÄ±lan kelimeler daha dÃ¼ÅŸÃ¼k bir aÄŸÄ±rlÄ±ÄŸa sahip olurken, nadir olanlar daha yÃ¼ksek bir aÄŸÄ±rlÄ±ÄŸa sahip olacaktÄ±r.\n",
    "\n",
    "TF(t) = (Bir t teriminin bir dÃ¶kÃ¼manda gÃ¶zlenme frekansÄ±) / (dÃ¶kÃ¼mandaki toplam terim sayÄ±sÄ±) \n",
    "\n",
    "IDF(t) = log_e(Toplam dÃ¶kÃ¼man sayÄ±sÄ± / iÃ§inde t terimi olan belge sayÄ±sÄ±)\n",
    "\n",
    "Link: https://medium.com/@acrosson/summarize-documents-using-tf-idf-bdee8f60b71\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer() \n",
    "vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_count = vectorizer.transform(train_x)\n",
    "x_test_count = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01', '02', '03']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[5:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_count.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-ID\n",
    "\n",
    "TF(t) = (Bir t teriminin bir dÃ¶kÃ¼manda gÃ¶zlenme frekansÄ±) / (dÃ¶kÃ¼mandaki toplam terim sayÄ±sÄ±)\n",
    "\n",
    "IDF(t) = log_e(Toplam dÃ¶kÃ¼man sayÄ±sÄ± / iÃ§inde t terimi olan belge sayÄ±sÄ±)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_word_vectorizer = TfidfVectorizer()\n",
    "tf_idf_word_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf_idf_word = tf_idf_word_vectorizer.transform(train_x)\n",
    "x_test_tf_idf_word = tf_idf_word_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(2, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_ngram_vectorizer = TfidfVectorizer(ngram_range = (2,3))\n",
    "tf_idf_ngram_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf_idf_ngram = tf_idf_ngram_vectorizer.transform(train_x)\n",
    "x_test_tf_idf_ngram = tf_idf_ngram_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CharLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(2, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_chars_vectorizer = TfidfVectorizer(analyzer = \"char\", ngram_range = (2,3))\n",
    "tf_idf_chars_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf_idf_chars = tf_idf_chars_vectorizer.transform(train_x)\n",
    "x_test_tf_idf_chars = tf_idf_chars_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makine Ã–ÄŸrenmesi ile Sentiment SÄ±nÄ±flandÄ±rmasÄ±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lojistik Regrasyon scikit-learn kÃ¼tÃ¼phanesi\n",
    "\n",
    "\n",
    "DuyarlÄ±lÄ±k Analizi, belirli bir ÅŸeye gÃ¶re birinin hissiyatÄ±nÄ± yargÄ±lamak veya duygularÄ±nÄ± anlamlandÄ±rmak iÃ§in kullanÄ±lan bir yÃ¶ntemdir. Temel olarak bir metin iÅŸleme (text processing) iÅŸlemi olup verilen metinin duygusal olarak\n",
    "ifade etmek istediÄŸi sÄ±nÄ±fÄ± belirlemeyi amaÃ§lar.\n",
    "- Metinlerin Ã¼zerinden amaca yÃ¶nelik olarak fikir Ã§Ä±karÄ±mÄ± yapÄ±lÄ±rken kelime sayÄ±sÄ±, isim, sÄ±fat, zarf veya fiil gibi kelimelerin sÄ±klÄ±klarÄ± (frekanslarÄ±) Ã¼zerinden fikir madenciliÄŸi yapÄ±lmasÄ±na verilen isimdir. (Word2vec , TF/ IDF)\n",
    "- Frekans tabanlÄ± fikir madenciliÄŸinde, Ã¶ncelikle isim kelime gruplarÄ± bulunarak bunlar uzunluklarÄ±na, kullanÄ±mdaki gerekliliklerine ve olumlu olumsuz kutupsallÄ±ÄŸÄ±na gÃ¶re sÄ±nÄ±flandÄ±rÄ±lmaktadÄ±r.\n",
    "\n",
    "### https://medium.com/operations-management-t%C3%BCrkiye/lojistik-regresyon-ile-duygu-analizi-d9d0b8e7b4e5\n",
    "### https://www.nltk.org/howto/sentiment.html\n",
    "### https://www.nltk.org/api/nltk.sentiment.html#module-nltk.sentiment\n",
    "### https://nlpforhackers.io/sentiment-analysis-intro/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lojistik Regrasyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors DoÄŸruluk OranÄ±: 0.8538\n",
      "Word-Level TF-IDF DoÄŸruluk OranÄ±: 0.86\n",
      "N-GRAM TF-IDF DoÄŸruluk OranÄ±: 0.8176\n",
      "CHARLEVEL DoÄŸruluk OranÄ±: 0.9568000000000001\n"
     ]
    }
   ],
   "source": [
    "loj = linear_model.LogisticRegression()\n",
    "loj_model = loj.fit(x_train_count, train_y)\n",
    "accuracy = model_selection.cross_val_score(loj_model, x_test_count, test_y, cv = 10).mean()\n",
    "accuracy=float(accuracy)\n",
    "print(\"Count Vectors DoÄŸruluk OranÄ±:\", accuracy)\n",
    "\n",
    "loj = linear_model.LogisticRegression()\n",
    "loj_model = loj.fit(x_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(loj_model, x_test_tf_idf_word, test_y, cv = 10).mean()\n",
    "print(\"Word-Level TF-IDF DoÄŸruluk OranÄ±:\", accuracy)\n",
    "\n",
    "loj = linear_model.LogisticRegression()\n",
    "loj_model = loj.fit(x_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(loj_model, x_test_tf_idf_ngram, test_y, cv = 10).mean()\n",
    "print(\"N-GRAM TF-IDF DoÄŸruluk OranÄ±:\", accuracy)\n",
    "\n",
    "loj = linear_model.LogisticRegression()\n",
    "loj_model = loj.fit(x_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(loj_model, x_test_tf_idf_chars, test_y, cv = 10).mean()\n",
    "print(\"CHARLEVEL DoÄŸruluk OranÄ±:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navy Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors DoÄŸruluk OranÄ±: 0.865\n",
      "Word-Level TF-IDF DoÄŸruluk OranÄ±: 0.8744\n",
      "N-GRAM TF-IDF DoÄŸruluk OranÄ±: 0.8366\n",
      "CHARLEVEL DoÄŸruluk OranÄ±: 0.8914\n"
     ]
    }
   ],
   "source": [
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(x_train_count,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, x_test_count, test_y, cv = 10).mean()\n",
    "print(\"Count Vectors DoÄŸruluk OranÄ±:\", accuracy)\n",
    "\n",
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(x_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, x_test_tf_idf_word, test_y, cv = 10).mean()\n",
    "print(\"Word-Level TF-IDF DoÄŸruluk OranÄ±:\", accuracy)\n",
    "\n",
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(x_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, x_test_tf_idf_ngram, test_y, cv = 10).mean()\n",
    "print(\"N-GRAM TF-IDF DoÄŸruluk OranÄ±:\", accuracy)\n",
    "\n",
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(x_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(nb_model, x_test_tf_idf_chars, test_y, cv = 10).mean()\n",
    "\n",
    "print(\"CHARLEVEL DoÄŸruluk OranÄ±:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors DoÄŸruluk OranÄ±: 0.8366\n",
      "Word-Level TF-IDF DoÄŸruluk OranÄ±: 0.8290000000000001\n",
      "N-GRAM TF-IDF DoÄŸruluk OranÄ±: 0.7792000000000001\n",
      "CHARLEVEL DoÄŸruluk OranÄ±: 0.9974000000000001\n"
     ]
    }
   ],
   "source": [
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = rf.fit(x_train_count,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, x_test_count, test_y,cv = 10).mean()\n",
    "print(\"Count Vectors DoÄŸruluk OranÄ±:\", accuracy)\n",
    "\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = rf.fit(x_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, x_test_tf_idf_word, test_y, cv = 10).mean()\n",
    "print(\"Word-Level TF-IDF DoÄŸruluk OranÄ±:\", accuracy)\n",
    "\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = rf.fit(x_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, x_test_tf_idf_ngram, test_y, cv = 10).mean()\n",
    "print(\"N-GRAM TF-IDF DoÄŸruluk OranÄ±:\", accuracy)\n",
    "\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_model = rf.fit(x_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(rf_model, x_test_tf_idf_chars, test_y, cv = 10).mean()\n",
    "print(\"CHARLEVEL DoÄŸruluk OranÄ±:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `RandomForestClassifier()` not found.\n"
     ]
    }
   ],
   "source": [
    "?RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectors DoÄŸruluk OranÄ±: 0.7830000000000001\n",
      "Word-Level TF-IDF DoÄŸruluk OranÄ±: 0.7824\n",
      "N-GRAM TF-IDF DoÄŸruluk OranÄ±: 0.6902\n",
      "CHARLEVEL DoÄŸruluk OranÄ±: 1.0\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(x_train_count,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, x_test_count, test_y, cv = 10).mean()\n",
    "print(\"Count Vectors DoÄŸruluk OranÄ±:\", accuracy)\n",
    "\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(x_train_tf_idf_word,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, x_test_tf_idf_word, test_y, cv = 10).mean()\n",
    "print(\"Word-Level TF-IDF DoÄŸruluk OranÄ±:\", accuracy)\n",
    "\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(x_train_tf_idf_ngram,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, x_test_tf_idf_ngram, test_y, cv = 10).mean()\n",
    "print(\"N-GRAM TF-IDF DoÄŸruluk OranÄ±:\", accuracy)\n",
    "\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb_model = xgb.fit(x_train_tf_idf_chars,train_y)\n",
    "accuracy = model_selection.cross_val_score(xgb_model, x_test_tf_idf_chars, test_y, cv = 10).mean()\n",
    "print(\"CHARLEVEL DoÄŸruluk OranÄ±:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('ArelUnuversitesi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radyosivrisinek kafaradyo radyoland yÄ±lÃ¶nceben...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bbsimsek arel Ã¼niversitesi metoroloji mÃ¼hendis...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ogrencidekani Ã§ocuklarÄ±n yeri eÄŸitim Ã¶ÄŸretim y...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ogrencidekani Ã§ocuklarÄ±n yeri eÄŸitim Ã¶ÄŸretim y...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ã§ocuklarÄ±n yeri eÄŸitim Ã¶ÄŸretim yuvalarÄ± parkla...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>ÅŸimdi bardaÄŸÄ±mÄ±zÄ± Ã¶nÃ¼mÃ¼ze alÄ±yoruz sÃ¼slemek is...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>kavanozumuzun kapaÄŸÄ±nÄ± kapattÄ±ÄŸÄ±mÄ±zdan emin ol...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>ilk olarak Ã§ay kaÅŸÄ±ÄŸÄ± granÃ¼l kahvemizi kavanoz...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>malzemeler kÃ¼Ã§Ã¼k boy kavanoz sÃ¼t granÃ¼l kahvet...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>buzlu soÄŸuk kahve tarifi httpstcolkhikfxaf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment\n",
       "0     radyosivrisinek kafaradyo radyoland yÄ±lÃ¶nceben...          2\n",
       "1     bbsimsek arel Ã¼niversitesi metoroloji mÃ¼hendis...          2\n",
       "2     ogrencidekani Ã§ocuklarÄ±n yeri eÄŸitim Ã¶ÄŸretim y...          2\n",
       "3     ogrencidekani Ã§ocuklarÄ±n yeri eÄŸitim Ã¶ÄŸretim y...          2\n",
       "4     Ã§ocuklarÄ±n yeri eÄŸitim Ã¶ÄŸretim yuvalarÄ± parkla...          2\n",
       "...                                                 ...        ...\n",
       "4398  ÅŸimdi bardaÄŸÄ±mÄ±zÄ± Ã¶nÃ¼mÃ¼ze alÄ±yoruz sÃ¼slemek is...          2\n",
       "4399  kavanozumuzun kapaÄŸÄ±nÄ± kapattÄ±ÄŸÄ±mÄ±zdan emin ol...          2\n",
       "4400  ilk olarak Ã§ay kaÅŸÄ±ÄŸÄ± granÃ¼l kahvemizi kavanoz...          2\n",
       "4401  malzemeler kÃ¼Ã§Ã¼k boy kavanoz sÃ¼t granÃ¼l kahvet...          2\n",
       "4402         buzlu soÄŸuk kahve tarifi httpstcolkhikfxaf          2\n",
       "\n",
       "[4403 rows x 2 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2331"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].iloc[7672:10003].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Analiz edilen verinin kayÄ±t edileceÄŸi csv dosyaya bir ad veriniz : ArelUnuversitesi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ä°ÅŸlem tamamlandÄ±\n",
      "0.0 dakikada toplam 2331 tweet analiz edildi\n"
     ]
    }
   ],
   "source": [
    "rf = TfidfVectorizer(analyzer = \"char\", ngram_range = (2,3))\n",
    "rf.fit(train_x)\n",
    "     \n",
    "dosya=input('Analiz edilen verinin kayÄ±t edileceÄŸi csv dosyaya bir ad veriniz :')\n",
    "\n",
    "for x in range(df['text'].count()):\n",
    "    baslangic=time.time()\n",
    "    \n",
    "    veri= pd.Series(df['text'][x])\n",
    "    veri = rf.transform(veri)\n",
    "\n",
    "    sonuc=rf_model.predict(veri)\n",
    "   \n",
    "    sonuc=int(sonuc)\n",
    "    \n",
    "    if sonuc == 1 :\n",
    "        df['sentiment'][x]=sonuc\n",
    "    else:\n",
    "        df['sentiment'][x]=sonuc\n",
    "df.to_csv(dosya+'.csv', mode='w',index=False)\n",
    "bitis=time.time()\n",
    "print('Ä°ÅŸlem tamamlandÄ±')\n",
    "print('{} dakikada toplam {} tweet analiz edildi'.format(round((bitis-baslangic)/60,2),sayi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radyosivrisinek kafaradyo radyoland yÄ±lÃ¶nceben...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bbsimsek arel Ã¼niversitesi metoroloji mÃ¼hendis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ogrencidekani Ã§ocuklarÄ±n yeri eÄŸitim Ã¶ÄŸretim y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ogrencidekani Ã§ocuklarÄ±n yeri eÄŸitim Ã¶ÄŸretim y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ã§ocuklarÄ±n yeri eÄŸitim Ã¶ÄŸretim yuvalarÄ± parkla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>ÅŸimdi bardaÄŸÄ±mÄ±zÄ± Ã¶nÃ¼mÃ¼ze alÄ±yoruz sÃ¼slemek is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>kavanozumuzun kapaÄŸÄ±nÄ± kapattÄ±ÄŸÄ±mÄ±zdan emin ol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>ilk olarak Ã§ay kaÅŸÄ±ÄŸÄ± granÃ¼l kahvemizi kavanoz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>malzemeler kÃ¼Ã§Ã¼k boy kavanoz sÃ¼t granÃ¼l kahvet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>buzlu soÄŸuk kahve tarifi httpstcolkhikfxaf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment\n",
       "0     radyosivrisinek kafaradyo radyoland yÄ±lÃ¶nceben...          1\n",
       "1     bbsimsek arel Ã¼niversitesi metoroloji mÃ¼hendis...          1\n",
       "2     ogrencidekani Ã§ocuklarÄ±n yeri eÄŸitim Ã¶ÄŸretim y...          0\n",
       "3     ogrencidekani Ã§ocuklarÄ±n yeri eÄŸitim Ã¶ÄŸretim y...          0\n",
       "4     Ã§ocuklarÄ±n yeri eÄŸitim Ã¶ÄŸretim yuvalarÄ± parkla...          1\n",
       "...                                                 ...        ...\n",
       "4398  ÅŸimdi bardaÄŸÄ±mÄ±zÄ± Ã¶nÃ¼mÃ¼ze alÄ±yoruz sÃ¼slemek is...          1\n",
       "4399  kavanozumuzun kapaÄŸÄ±nÄ± kapattÄ±ÄŸÄ±mÄ±zdan emin ol...          1\n",
       "4400  ilk olarak Ã§ay kaÅŸÄ±ÄŸÄ± granÃ¼l kahvemizi kavanoz...          1\n",
       "4401  malzemeler kÃ¼Ã§Ã¼k boy kavanoz sÃ¼t granÃ¼l kahvet...          1\n",
       "4402         buzlu soÄŸuk kahve tarifi httpstcolkhikfxaf          1\n",
       "\n",
       "[4403 rows x 2 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>timeline</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>location</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1271463341144276998</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1077402606...</td>\n",
       "      <td>@RadyoSivrisinek @kafaradyo @radyoland #10YÄ±lÃ–...</td>\n",
       "      <td>2020-06-12 15:24:17</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>SevdaAkcasu</td>\n",
       "      <td>1102</td>\n",
       "      <td>Ankara'da</td>\n",
       "      <td>[{'text': '10YÄ±lÃ–nceBen', 'indices': [39, 52]}]</td>\n",
       "      <td>SevdaAkcasu</td>\n",
       "      <td>Ankara'da</td>\n",
       "      <td>8065</td>\n",
       "      <td>1082</td>\n",
       "      <td>12161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1270464754205831170</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1270807390...</td>\n",
       "      <td>SARI PAPATYA GÄ°TMEMEN LAZIMDI \\n.\\n.\\n.\\n#surv...</td>\n",
       "      <td>2020-06-09 21:16:16</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>arel_ern</td>\n",
       "      <td>224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'text': 'survivor2020', 'indices': [37, 50]}]</td>\n",
       "      <td>arel_ern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1658</td>\n",
       "      <td>267</td>\n",
       "      <td>5312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1270325535890182145</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1267557561...</td>\n",
       "      <td>ðŸ¦„|-HayatÄ±nÄ±zÄ±n yaklaÅŸÄ±k 6â€™da 1â€™i Ã§arÅŸamba gÃ¼nl...</td>\n",
       "      <td>2020-06-09 12:03:03</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>selfcare__arel_</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>selfcare__arel_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1270326827748405250</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1267557561...</td>\n",
       "      <td>ðŸ¦„| Daha fazla bu tarz gÃ¶nderi gelmesi iÃ§in beÄŸ...</td>\n",
       "      <td>2020-06-09 12:08:11</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>selfcare__arel_</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>selfcare__arel_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1270394791604477955</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1269030619...</td>\n",
       "      <td>@zalimmgeceler @izellll_ YaptÄ±m zaten Arel Ã¼ni...</td>\n",
       "      <td>2020-06-09 16:38:15</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>fuurkanates</td>\n",
       "      <td>52558</td>\n",
       "      <td>Bursa</td>\n",
       "      <td>[]</td>\n",
       "      <td>fuurkanates</td>\n",
       "      <td>Bursa</td>\n",
       "      <td>28710</td>\n",
       "      <td>35807</td>\n",
       "      <td>39586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1270630907666407424</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1242186829...</td>\n",
       "      <td>RT @birsucann: DÃ¼nyada; 35 Ã¼lkede heykeli, 120...</td>\n",
       "      <td>2020-06-10 08:16:30</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>337</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Hsyn_Arel_Ayse</td>\n",
       "      <td>23</td>\n",
       "      <td>Buca, Ä°zmir</td>\n",
       "      <td>[]</td>\n",
       "      <td>Hsyn_Arel_Ayse</td>\n",
       "      <td>Buca, Ä°zmir</td>\n",
       "      <td>281</td>\n",
       "      <td>174</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1271113674397233153</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1271019329...</td>\n",
       "      <td>~Onlara ihtiyacÄ±n olduÄŸu zaman kaybolurlar \\n~...</td>\n",
       "      <td>2020-06-11 16:14:50</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>arel_selfcare</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>arel_selfcare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1270295988129992704</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1270461971...</td>\n",
       "      <td>RT @SufleninVasisi: AREL Ãœniversitesi 2016 mez...</td>\n",
       "      <td>2020-06-09 10:05:39</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>kivircikcik23</td>\n",
       "      <td>482</td>\n",
       "      <td>Ä°stanbul, TÃ¼rkiye</td>\n",
       "      <td>[{'text': 'muratyurtgÃ¼l', 'indices': [103, 116]}]</td>\n",
       "      <td>kivircikcik23</td>\n",
       "      <td>Ä°stanbul, TÃ¼rkiye</td>\n",
       "      <td>1447</td>\n",
       "      <td>312</td>\n",
       "      <td>15869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1271117765995384832</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1271019329...</td>\n",
       "      <td>ðŸ’«|KÃ¶tÃ¼ arkadaÅŸlarÄ±nÄ± tespit etme https://t.co/...</td>\n",
       "      <td>2020-06-11 16:31:06</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>arel_selfcare</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>arel_selfcare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1270828287699361792</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1249042250...</td>\n",
       "      <td>@pekiiiozamaan @bbarisgunes YankÄ± Arel</td>\n",
       "      <td>2020-06-10 21:20:49</td>\n",
       "      <td>&lt;bound method User.timeline of User(_api=&lt;twee...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>buseeazmn</td>\n",
       "      <td>871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>buseeazmn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2844</td>\n",
       "      <td>60</td>\n",
       "      <td>50752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                  profile_image_url  \\\n",
       "0   1271463341144276998  http://pbs.twimg.com/profile_images/1077402606...   \n",
       "59  1270464754205831170  http://pbs.twimg.com/profile_images/1270807390...   \n",
       "70  1270325535890182145  http://pbs.twimg.com/profile_images/1267557561...   \n",
       "69  1270326827748405250  http://pbs.twimg.com/profile_images/1267557561...   \n",
       "67  1270394791604477955  http://pbs.twimg.com/profile_images/1269030619...   \n",
       "..                  ...                                                ...   \n",
       "55  1270630907666407424  http://pbs.twimg.com/profile_images/1242186829...   \n",
       "18  1271113674397233153  http://pbs.twimg.com/profile_images/1271019329...   \n",
       "77  1270295988129992704  http://pbs.twimg.com/profile_images/1270461971...   \n",
       "17  1271117765995384832  http://pbs.twimg.com/profile_images/1271019329...   \n",
       "43  1270828287699361792  http://pbs.twimg.com/profile_images/1249042250...   \n",
       "\n",
       "                                                 text           created_at  \\\n",
       "0   @RadyoSivrisinek @kafaradyo @radyoland #10YÄ±lÃ–...  2020-06-12 15:24:17   \n",
       "59  SARI PAPATYA GÄ°TMEMEN LAZIMDI \\n.\\n.\\n.\\n#surv...  2020-06-09 21:16:16   \n",
       "70  ðŸ¦„|-HayatÄ±nÄ±zÄ±n yaklaÅŸÄ±k 6â€™da 1â€™i Ã§arÅŸamba gÃ¼nl...  2020-06-09 12:03:03   \n",
       "69  ðŸ¦„| Daha fazla bu tarz gÃ¶nderi gelmesi iÃ§in beÄŸ...  2020-06-09 12:08:11   \n",
       "67  @zalimmgeceler @izellll_ YaptÄ±m zaten Arel Ã¼ni...  2020-06-09 16:38:15   \n",
       "..                                                ...                  ...   \n",
       "55  RT @birsucann: DÃ¼nyada; 35 Ã¼lkede heykeli, 120...  2020-06-10 08:16:30   \n",
       "18  ~Onlara ihtiyacÄ±n olduÄŸu zaman kaybolurlar \\n~...  2020-06-11 16:14:50   \n",
       "77  RT @SufleninVasisi: AREL Ãœniversitesi 2016 mez...  2020-06-09 10:05:39   \n",
       "17  ðŸ’«|KÃ¶tÃ¼ arkadaÅŸlarÄ±nÄ± tespit etme https://t.co/...  2020-06-11 16:31:06   \n",
       "43             @pekiiiozamaan @bbarisgunes YankÄ± Arel  2020-06-10 21:20:49   \n",
       "\n",
       "                                             timeline  retweeted  \\\n",
       "0   <bound method User.timeline of User(_api=<twee...      False   \n",
       "59  <bound method User.timeline of User(_api=<twee...      False   \n",
       "70  <bound method User.timeline of User(_api=<twee...      False   \n",
       "69  <bound method User.timeline of User(_api=<twee...      False   \n",
       "67  <bound method User.timeline of User(_api=<twee...      False   \n",
       "..                                                ...        ...   \n",
       "55  <bound method User.timeline of User(_api=<twee...      False   \n",
       "18  <bound method User.timeline of User(_api=<twee...      False   \n",
       "77  <bound method User.timeline of User(_api=<twee...      False   \n",
       "17  <bound method User.timeline of User(_api=<twee...      False   \n",
       "43  <bound method User.timeline of User(_api=<twee...      False   \n",
       "\n",
       "    retweet_count               source user_screen_name  user_followers_count  \\\n",
       "0               0  Twitter for Android      SevdaAkcasu                  1102   \n",
       "59              0   Twitter for iPhone         arel_ern                   224   \n",
       "70              0   Twitter for iPhone  selfcare__arel_                     4   \n",
       "69              0   Twitter for iPhone  selfcare__arel_                     4   \n",
       "67              0  Twitter for Android      fuurkanates                 52558   \n",
       "..            ...                  ...              ...                   ...   \n",
       "55            337   Twitter for iPhone   Hsyn_Arel_Ayse                    23   \n",
       "18              1  Twitter for Android    arel_selfcare                     2   \n",
       "77              7   Twitter for iPhone    kivircikcik23                   482   \n",
       "17              0  Twitter for Android    arel_selfcare                     2   \n",
       "43              0  Twitter for Android        buseeazmn                   871   \n",
       "\n",
       "        user_location                                           Hashtags  \\\n",
       "0          Ankara'da     [{'text': '10YÄ±lÃ–nceBen', 'indices': [39, 52]}]   \n",
       "59                NaN    [{'text': 'survivor2020', 'indices': [37, 50]}]   \n",
       "70                NaN                                                 []   \n",
       "69                NaN                                                 []   \n",
       "67              Bursa                                                 []   \n",
       "..                ...                                                ...   \n",
       "55        Buca, Ä°zmir                                                 []   \n",
       "18                NaN                                                 []   \n",
       "77  Ä°stanbul, TÃ¼rkiye  [{'text': 'muratyurtgÃ¼l', 'indices': [103, 116]}]   \n",
       "17                NaN                                                 []   \n",
       "43                NaN                                                 []   \n",
       "\n",
       "        screen_name           location  statuses_count  friends_count  \\\n",
       "0       SevdaAkcasu         Ankara'da             8065           1082   \n",
       "59         arel_ern                NaN            1658            267   \n",
       "70  selfcare__arel_                NaN             178              3   \n",
       "69  selfcare__arel_                NaN             178              3   \n",
       "67      fuurkanates              Bursa           28710          35807   \n",
       "..              ...                ...             ...            ...   \n",
       "55   Hsyn_Arel_Ayse        Buca, Ä°zmir             281            174   \n",
       "18    arel_selfcare                NaN              11              2   \n",
       "77    kivircikcik23  Ä°stanbul, TÃ¼rkiye            1447            312   \n",
       "17    arel_selfcare                NaN              11              2   \n",
       "43        buseeazmn                NaN            2844             60   \n",
       "\n",
       "    favourites_count  sentiment  \n",
       "0              12161          1  \n",
       "59              5312          1  \n",
       "70                 5          1  \n",
       "69                 5          1  \n",
       "67             39586          1  \n",
       "..               ...        ...  \n",
       "55               475          0  \n",
       "18                 0          0  \n",
       "77             15869          0  \n",
       "17                 0          0  \n",
       "43             50752          0  \n",
       "\n",
       "[100 rows x 18 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='sentiment',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "cÃ¼mle= pd.Series('BugÃ¼n hava Ã§ok iyi deÄŸil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rf = TfidfVectorizer(analyzer = \"char\", ngram_range = (2,3))\n",
    "rf.fit(train_x)\n",
    "\n",
    "veri = rf.transform(cÃ¼mle)\n",
    "\n",
    "sonuc=rf_model.predict(veri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer = \"char\", ngram_range = (2,3))\n",
    "tf.fit(train_x)\n",
    "\n",
    "veri = tf.transform(cÃ¼mle)\n",
    "sonuc=loj_model.predict(veri) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "sentiment      \n",
       "0          1452\n",
       "1          2951"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
