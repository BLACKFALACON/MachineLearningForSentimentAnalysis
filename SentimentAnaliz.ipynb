{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kütüphanelerin eklenmesi\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19999 entries, 1 to 19999\n",
      "Data columns (total 1 columns):\n",
      "yorum    19999 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 312.5+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6447      gelmiş geçmiş en iyi film olduğunu düşünüyoru...\n",
      "19129     filmi geçen gece izledim ve ağlamaktan resmen...\n",
      "14548     ya ben açıkçası pek beğenmedim bu filmi yani ...\n",
      "12834     Tam bir hayal kırıklığı. Bundan iyi bir savaş...\n",
      "6666      filmi izleyeli baya oldu ama hala aklıma takı...\n",
      "Name: yorum, dtype: object\n",
      "\n",
      "\n",
      "X_train shape:  (14999,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8791392763384052\n",
      "Negatif: \n",
      "['berbat' 'beğenmedim' 'sıkıcı' 'rezalet' 'vasat' 'değmez' 'gereksiz'\n",
      " 'sıkıldım' 'kötü' 'etmiyorum']\n",
      "\n",
      "Pozitif: \n",
      "['beğendim' 'mükemmel' 'müthiş' 'harika' 'söze' 'başyapıt' 'izlenmeli'\n",
      " 'zleyin' 'sıkılmadan' 'muhteşem']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8789689969970661\n",
      "En küçük Tfidf: \n",
      "['tazegül' 'durumla' 'isi' 'report' 'dönmesi' 'düşünme' 'öfke'\n",
      " 'karşımızdaki' 'oturan' 'kuzey']\n",
      "\n",
      "En büyük Tfidf: \n",
      "['basit' 'ben' 'etkileyici' 'vasat' 'cok' 'yorumsuz' 'izleyin' 'bence'\n",
      " 'erkek' 'sevmedim']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8763568734920516\n",
      "Negatif: \n",
      "['berbat' 'beğenmedim' 'rezalet' 'sıkıcı' 'en kötü' 'değmez' 'mahsun'\n",
      " 'gereksiz' 'vasat' 'yahudi']\n",
      "\n",
      "Pozitif Coef: \n",
      "['10 10' 'mükemmel' 'beğendim' 'müthiş' 'filme kötü' 'harika' 'izlenmeli'\n",
      " 'rocky' 'başyapıt' 'budur']\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Yorumunuz Nedir?(Programdan çıkmak için 'F' yazınız) f\n"
     ]
    }
   ],
   "source": [
    "#Veri setinin eklenip başlığının belirlenmesi\n",
    "column = ['yorum']\n",
    "df = pd.read_csv('yorumlar.csv', encoding ='iso-8859-9', sep='\"')\n",
    "df.columns=column\n",
    "df.info()\n",
    "df.head()\n",
    "\n",
    "#df.dropna(inplace=True)\n",
    "\n",
    "#Veri setindeki Türkçe dolgu kelimelerinin kaldırılması\n",
    "def remove_stopwords(df_fon):\n",
    "    stopwords = open('turkce-stop-words', 'r').read().split()\n",
    "    df_fon['stopwords_removed'] = list(map(lambda doc:\n",
    "        [word for word in doc if word not in stopwords], df_fon['yorum']))\n",
    "\n",
    "remove_stopwords(df)\n",
    "\n",
    "\n",
    "#Verisetinde Positivity adlı bir sütunun oluşturalım ve başlangıçta tüm değerlere olumlu olarak 1 değerinin atayalım\n",
    "df['Positivity'] = 1\n",
    "\n",
    "#Veri setimizde 10003. veri ve sonrasındaki veriler olumsuz(negatif) verilerdir bu yüzden bu değerlerin\n",
    "#Positivity değerleri 0 ile değiştirelim.\n",
    "df.Positivity.iloc[10003:] = 0\n",
    "\n",
    "#Şimdi, verileri \"yorum\" ve \"Positivity\" sütunlarını kullanarak rastgele eğitim ve test alt kümelerini bölüştürelim ve \n",
    "#ardından ilk girişi ve eğitim setinin şeklini yazalım.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['yorum'], df['Positivity'], random_state = 0)\n",
    "print(X_train.head())\n",
    "print('\\n\\nX_train shape: ', X_train.shape)\n",
    "\n",
    "#CountVectorizer'ı başlatıyoruz ve eğitim verilerimize uyguluyoruz.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(encoding ='iso-8859-9').fit(X_train)\n",
    "\n",
    "#X_train'deki belgeleri bir belge terim matrisine dönüştürürüz\n",
    "X_train_vectorized = vect.transform(X_train) \n",
    "\n",
    "#Bu özellik matrisi X_ train_ vectorized'e dayanarak Lojistik Regresyon sınıflandırıcısını eğiteceğiz\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#Daha sonra, X_test kullanarak tahminler yapacağız ve eğri puanının altındaki alanı hesaplayacağız.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "\n",
    "#Modelimizin bu tahminleri nasıl yaptığını daha iyi anlamak için, her bir özellik için katsayıları (bir kelime), \n",
    "#pozitifliği ve olumsuzluk açısından ağırlığını belirlemek için kullanabiliriz.\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "print('Negatif: \\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Pozitif: \\n{}\\n'.format(feature_names[sorted_coef_index[:-11:-1]]))\n",
    "\n",
    "\n",
    "#tf-idf vectorizer'ı başlatacağız ve eğitim verilerimize uygulayacağız. \n",
    "#En az beş dokümanda görünen kelime dağarcığımızdaki kelimeleri kaldıracağımız min_df = 5 değerini belirtiyoruz.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(min_df = 5).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))  \n",
    "\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "print('En küçük Tfidf: \\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
    "print('En büyük Tfidf: \\n{}\\n'.format(feature_names[sorted_tfidf_index[:-11:-1]]))\n",
    "\n",
    "\n",
    "#bigramlar, bitişik kelimelerin çiftlerini sayar ve bize kötü ve kötü olmayan gibi özellikler verebilir. \n",
    "#Bu nedenle, minimum 5 belge sıklığını belirten ve 1 gram ve 2 gram ekstrakt eden eğitim setimizi yeniden yerleştiriyoruz.\n",
    "vect = CountVectorizer(min_df = 5, ngram_range = (1,2)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "\n",
    "#Her özelliği kontrol etmek için katsayıları kullanarak görebiliriz\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "print('Negatif: \\n{}\\n'.format(feature_names[sorted_coef_index][:10]))\n",
    "print('Pozitif Coef: \\n{}\\n'.format(feature_names[sorted_coef_index][:-11:-1]))\n",
    "\n",
    "while(True):\n",
    "    yorum=input(\"Yorumunuz Nedir?(Programdan çıkmak için \\'F\\' yazınız)\")\n",
    "    if(yorum == 'F' or yorum == 'f'):\n",
    "        break\n",
    "    else:\n",
    "        print(model.predict(vect.transform([yorum])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
